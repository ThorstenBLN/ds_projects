{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, KBinsDiscretizer, FunctionTransformer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data\n",
    "full = pd.read_csv('../data/train.csv', sep=',', index_col=0)\n",
    "# split it in X and y data\n",
    "X = full.drop(['Survived'], axis=1) # drop 'Survived' as column\n",
    "y = full['Survived'] # select only the 'Survived' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test data\n",
    "full_test = pd.read_csv('../data/test.csv', delimiter=',', index_col=0)\n",
    "Xtest = full_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Feature engineering / data preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering for numericals\n",
    "age_feature = [\"Age\"]\n",
    "# create a sequential pipeline for Age Feature\n",
    "age_transformer = make_pipeline(\n",
    "    KNNImputer(), \n",
    "    KBinsDiscretizer(n_bins=15, strategy='quantile', encode='onehot')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering for categorical variables\n",
    "categorical_features = ['Sex', 'Pclass']\n",
    "# create a transformer for categorical values\n",
    "categorical_transformer = OneHotEncoder(drop='first', sparse=False, handle_unknown='ignore')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Scaler for Parch and SibSp\n",
    "scale_features = ['Parch', 'SibSp']\n",
    "scale_transformer = MinMaxScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to extract info from name. Will be used via Functiontransformer\n",
    "def title_extraction(df):\n",
    "    '''extracts the title from the name feature,\n",
    "    clusters it into 4 categories: 0: special title (e.g. Colonel, Baron), 1: Mr, 2: Mrs, 3: Miss\n",
    "    and returns a dataframe with the title class'''\n",
    "    # extract the 1. part of the 1st name \n",
    "    title = df['Name'].str.split(',', expand = True)\n",
    "    title = title[title.columns[1]].str.split('.', expand = True)\n",
    "    title = title[title.columns[0]]\n",
    "    title = title.str.strip()\n",
    "    # transform series to dataframe and add column-title\n",
    "    df_title = pd.DataFrame(data=title)\n",
    "    df_title.columns=['Title']\n",
    "    # group the extracted titles\n",
    "    df_title['Title_no'] = 0\n",
    "    df_title.loc[df_title['Title'] == 'Mr', 'Title_no'] = 1\n",
    "    df_title.loc[df_title['Title'] == 'Mrs', 'Title_no'] = 2\n",
    "    df_title.loc[df_title['Title'] == 'Miss', 'Title_no'] = 3\n",
    "    df_title.drop(['Title'], axis= 1, inplace=True)\n",
    "    return df_title\n",
    "\n",
    "# create transformer for title\n",
    "title_feature = ['Name']\n",
    "title_transformer = make_pipeline(\n",
    "    FunctionTransformer(title_extraction), \n",
    "    OneHotEncoder(drop='first', sparse=False, handle_unknown='ignore')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - NOT USED - feature engineering for relatives - NOT USED -\n",
    "# add the column for 'realtives'\n",
    "# X['Relatives'] = X['SibSp'] + X['Parch']\n",
    "# Xtest['Relatives'] = Xtest['SibSp'] + Xtest['Parch']\n",
    "# relative_feature = ['Relatives']\n",
    "# relative_transformer = KBinsDiscretizer(n_bins=5, strategy='kmeans', encode='onehot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- NOT USED -- Fare Transformer -- NOT USED --\n",
    "# fare_feature = ['Fare']\n",
    "# fare_transformer = make_pipeline(\n",
    "#     SimpleImputer(strategy=\"mean\"), \n",
    "#     KBinsDiscretizer(n_bins=5, encode='onehot', strategy='quantile')\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the transformer preprocessor (ColumnTransformer works parallel)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"age\", age_transformer, age_feature),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "        ('scale', scale_transformer, scale_features),\n",
    "        ('title', title_transformer, title_feature),\n",
    "    ],\n",
    "    remainder='drop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Pipeline with RFC Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model pipeline (works sequential)\n",
    "pipeline = make_pipeline(preprocessor, RandomForestClassifier(n_estimators=130, criterion=\"gini\", max_depth=15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thorsten/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_discretization.py:230: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8929188255613126, 0.8365384615384616)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split data to train and test\n",
    "Xtrain, Xval, ytrain, yval = train_test_split(X, y, test_size=0.35, random_state=42)\n",
    "# fit the preprocessor and train model\n",
    "pipeline.fit(Xtrain, ytrain)\n",
    "pipeline.score(Xtrain, ytrain), pipeline.score(Xval, yval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create test predictions and Kaggle upload file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived\n",
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the test dataset \n",
    "predict_test = pipeline.predict(Xtest)\n",
    "df_predict = pd.DataFrame(data=predict_test, columns=['Survived'], dtype='int')\n",
    "df_predict.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataset of passenger ID and predictions\n",
    "full_test.reset_index(inplace=True)\n",
    "full_test = full_test[['PassengerId']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the data\n",
    "final_result = pd.merge(full_test, df_predict, left_index=True, right_index=True)\n",
    "# create upload file\n",
    "final_result.to_csv('final_result.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d01013faa6268d9b541af39e21e51ae91e81e71b63bd76f73433c553979f7595"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
