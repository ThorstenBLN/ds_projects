{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import sklearn.metrics as metrics\n",
    "from imblearn.pipeline import make_pipeline as mp_imb\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Functions for step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lyrics_list(root_dir, artist_list):\n",
    "    \"\"\"\n",
    "    returns 2D list: 1. Column: lyrics 2. Column: artist\n",
    "    iterates over the files in each artist folder to extract the lyrics\n",
    "    \"\"\"\n",
    "    master_list = []\n",
    "    for artist in artist_list:\n",
    "        for file_name in os.listdir(f\"{root_dir}{artist}\"):\n",
    "            text = open(f\"{root_dir}{artist}/{file_name}\").read()\n",
    "            text = text.replace('\\n', ' ') # replacing \\n in the text with whitespace\n",
    "            text = text.lower()\n",
    "            master_list.append([text, artist])\n",
    "    return master_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(data):\n",
    "    \"\"\"\n",
    "    creates a Dataframe out of 2D-list with 1. column: lyrics, 2nd column: artist and returns it\n",
    "    \"\"\"\n",
    "    return pd.DataFrame(data, columns=['lyrics_X', 'artist_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(ytrue, ypred, model, artist_pred_dict, artist_list):\n",
    "    \"\"\"\n",
    "    evaluates the model by accuracy and calculates the presicion, recall and F1 value for each artist\n",
    "    \"\"\"\n",
    "    print(f'{model}: ')\n",
    "    print(f'accuracy: {round(metrics.accuracy_score(ytrue, ypred), 3)}')\n",
    "    for artist in artist_list:\n",
    "        precision = round(metrics.precision_score(artist_pred_dict[artist][0], artist_pred_dict[artist][1]), 3)\n",
    "        recall = round(metrics.recall_score(artist_pred_dict[artist][0], artist_pred_dict[artist][1]), 3)\n",
    "        f1_score = round(metrics.f1_score(artist_pred_dict[artist][0], artist_pred_dict[artist][1]), 3)\n",
    "        print(f\"{artist}: precision: {precision}, recall: {recall}, F1 Score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_for_artist(yval, ypred, artist_list):\n",
    "    \"\"\"\n",
    "    returns a dictionary\n",
    "    keys: artists, \n",
    "    values: 2 lists \n",
    "    1st list: true value for artist (1 or 0) for all situations in which yval or ypredict labeled the artist\n",
    "    2nd list: predicted value for artist (1 or 0) for all situations in which yval or ypredict labeled the artist\n",
    "    these 2 lists are necessary to calculate the TP, FP, FN which are needed to calculate the metrics\n",
    "    \"\"\"\n",
    "    artist_pred_dict = {artist: [[int(1) if val == artist else int(0) for val, pred in zip(yval, ypred) if (val == artist or pred == artist)],\n",
    "                                [int(1) if pred == artist else int(0) for val, pred in zip(yval, ypred) if (val == artist or pred == artist)]]\n",
    "                                for artist in artist_list}\n",
    "    return artist_pred_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create a dataframe with lyrics and corresponding artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist_y     \n",
       "Frank_Sinatra    199\n",
       "Johnny_Cash      178\n",
       "Eminem           147\n",
       "Madonna          137\n",
       "Bob_Marley       114\n",
       "The_Kooks         94\n",
       "Amy_Winehouse     85\n",
       "dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_dir = '../data/songs3/'\n",
    "# get the artist names from the directory names\n",
    "artist_list = os.listdir(root_dir)\n",
    "# get a 2D list. axis 1: list with Lyrics & artist for each song. axis 0: all songs of all artists\n",
    "lyrics_list = get_lyrics_list(root_dir, artist_list)\n",
    "# create a dataframe with artists and lyrics as columns\n",
    "df_train = create_dataframe(lyrics_list)\n",
    "# train test split\n",
    "Xtrain, Xval, ytrain, yval = train_test_split(df_train['lyrics_X'], df_train['artist_y'], test_size=0.1, random_state=42)\n",
    "# check if target data is balanced\n",
    "pd.DataFrame(ytrain).value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create pipelines with gridsearch hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use an tf-idf-vectorizer, an RandomOverSampler (to balance the imbalanced lyric documents) \n",
    "# and the Multinomial-Naive-Bayes Classifier to classify the lyrics\n",
    "pipeline1 = mp_imb(TfidfVectorizer(stop_words='english', ngram_range=(1, 1)), \n",
    "                    RandomOverSampler(random_state=42, sampling_strategy={'Amy_Winehouse': 160,\n",
    "                            'The_Kooks':160, 'Bob_Marley': 160, 'Madonna': 160}),\n",
    "                    MultinomialNB())\n",
    "# pipeline1.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an alternative pipeline with a a RandomForestClassifier and a different over-sampling strategy \n",
    "pipeline2 = mp_imb(TfidfVectorizer(stop_words='english', ngram_range=(1, 1)), \n",
    "                    RandomOverSampler(random_state=42, sampling_strategy={'Amy_Winehouse': 180,\n",
    "                            'The_Kooks':180, 'Bob_Marley': 180, 'Madonna': 180}),\n",
    "                    RandomForestClassifier(n_estimators=100, max_depth=15, class_weight='balanced'))\n",
    "# pipeline2.get_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter optimization for the Multinomial Naive Bayes Classifier\n",
    "use_code = False\n",
    "if use_code:\n",
    "    params1 = {'tfidfvectorizer__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
    "                'multinomialnb__alpha': [0.3, 0.4, 0.5, 0.6],\n",
    "                'randomoversampler__sampling_strategy': [{'Amy_Winehouse': 165, 'The_Kooks': 165, 'Bob_Marley': 165, 'Madonna': 165},\n",
    "                                                        {'Amy_Winehouse': 130, 'The_Kooks': 130, 'Bob_Marley': 160, 'Madonna': 160}]\n",
    "                }\n",
    "    gs = GridSearchCV(pipeline1, params1, cv=6)\n",
    "    gs.fit(Xtrain, ytrain)\n",
    "    print(gs.best_params_)\n",
    "    print(gs.best_score_)\n",
    "    pd.DataFrame(gs.cv_results_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter optimization for the Random Forest Classifier\n",
    "use_code = False\n",
    "if use_code:\n",
    "    params2 = { #'tfidfvectorizer__ngram_range': [(1, 1)],\n",
    "                'randomforestclassifier__max_depth': [24, 26, 28],\n",
    "                'randomforestclassifier__n_estimators': [120, 122, 124],\n",
    "                'randomforestclassifier__class_weight': [None, 'balanced'],\n",
    "                'randomoversampler__sampling_strategy': [{'Amy_Winehouse': 165, 'The_Kooks': 165, 'Bob_Marley': 165, 'Madonna': 165},\n",
    "                                                        {'Amy_Winehouse': 130, 'The_Kooks': 130, 'Bob_Marley': 160, 'Madonna': 160}]\n",
    "                }\n",
    "    gs2 = GridSearchCV(pipeline2, params2, cv=6)\n",
    "    gs2.fit(Xtrain, ytrain)\n",
    "    print(gs2.best_params_)\n",
    "    print(gs2.best_score_)\n",
    "    pd.DataFrame(gs2.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thorsten/anaconda3/lib/python3.9/site-packages/imblearn/utils/_validation.py:299: UserWarning: After over-sampling, the number of samples (200) in class Amy_Winehouse will be larger than the number of samples in the majority class (class #Frank_Sinatra -> 199)\n",
      "  warnings.warn(\n",
      "/home/thorsten/anaconda3/lib/python3.9/site-packages/imblearn/utils/_validation.py:299: UserWarning: After over-sampling, the number of samples (200) in class The_Kooks will be larger than the number of samples in the majority class (class #Frank_Sinatra -> 199)\n",
      "  warnings.warn(\n",
      "/home/thorsten/anaconda3/lib/python3.9/site-packages/imblearn/utils/_validation.py:299: UserWarning: After over-sampling, the number of samples (200) in class Bob_Marley will be larger than the number of samples in the majority class (class #Frank_Sinatra -> 199)\n",
      "  warnings.warn(\n",
      "/home/thorsten/anaconda3/lib/python3.9/site-packages/imblearn/utils/_validation.py:299: UserWarning: After over-sampling, the number of samples (200) in class Madonna will be larger than the number of samples in the majority class (class #Frank_Sinatra -> 199)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9832 0.6916\n",
      "RFC: \n",
      "accuracy: 0.692\n",
      "Eminem: precision: 0.923, recall: 0.857, F1 Score: 0.889\n",
      "The_Kooks: precision: 0.556, recall: 0.625, F1 Score: 0.588\n",
      "Madonna: precision: 1.0, recall: 0.522, F1 Score: 0.686\n",
      "Bob_Marley: precision: 0.867, recall: 0.812, F1 Score: 0.839\n",
      "Amy_Winehouse: precision: 1.0, recall: 0.833, F1 Score: 0.909\n",
      "Johnny_Cash: precision: 0.647, recall: 0.524, F1 Score: 0.579\n",
      "Frank_Sinatra: precision: 0.444, recall: 0.842, F1 Score: 0.582\n"
     ]
    }
   ],
   "source": [
    "# RF-Classifier pipeline with the best results from the prior hyperparameter optimization\n",
    "pipeline3 = mp_imb(TfidfVectorizer(stop_words='english', ngram_range=(1, 1)), \n",
    "                            RandomOverSampler(random_state=42, sampling_strategy={'Amy_Winehouse': 200,\n",
    "                            'The_Kooks':200, 'Bob_Marley': 200, 'Madonna': 200}),\n",
    "                            RandomForestClassifier(max_depth=24, n_estimators=120, class_weight='balanced'))\n",
    "# fit the pipeline and calculate the overall train and validation accuracy\n",
    "pipeline3.fit(Xtrain,ytrain)\n",
    "print(round(pipeline3.score(Xtrain, ytrain), 4), round(pipeline3.score(Xval, yval), 4))\n",
    "# get the necessary lists to calculate TP, FP, FN for each artist (which are needed for the metrics)\n",
    "yval_pred = pipeline3.predict(Xval)\n",
    "artist_pred_dict = get_prediction_for_artist(list(yval), yval_pred, artist_list)\n",
    "# evaluate the model for each artist with precision, recall and F1 score of the validation data\n",
    "evaluate_model(yval, yval_pred, 'RFC', artist_pred_dict, artist_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9706 0.7196\n",
      "MNB: \n",
      "accuracy: 0.72\n",
      "Eminem: precision: 0.778, recall: 1.0, F1 Score: 0.875\n",
      "The_Kooks: precision: 0.5, recall: 0.5, F1 Score: 0.5\n",
      "Madonna: precision: 0.824, recall: 0.609, F1 Score: 0.7\n",
      "Bob_Marley: precision: 0.923, recall: 0.75, F1 Score: 0.828\n",
      "Amy_Winehouse: precision: 0.417, recall: 0.833, F1 Score: 0.556\n",
      "Johnny_Cash: precision: 0.765, recall: 0.619, F1 Score: 0.684\n",
      "Frank_Sinatra: precision: 0.682, recall: 0.789, F1 Score: 0.732\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes-Classifier pipeline with the best results from the prior hyperparameter optimization\n",
    "pipeline4 = mp_imb(TfidfVectorizer(stop_words='english', ngram_range=(1, 1)),  \n",
    "                            RandomOverSampler(random_state=42, sampling_strategy={'Amy_Winehouse': 180,\n",
    "                            'The_Kooks':180, 'Bob_Marley': 180, 'Madonna': 180}),\n",
    "                            MultinomialNB(alpha=0.6))\n",
    "# fit the pipeline and calculate the overall train and validation accuracy\n",
    "pipeline4.fit(Xtrain,ytrain)\n",
    "print(round(pipeline4.score(Xtrain, ytrain), 4), round(pipeline4.score(Xval, yval), 4))\n",
    "# get the necessary lists to calculate TP, FP, FN for each artist (which are needed for the metrics)\n",
    "yval_pred = pipeline4.predict(Xval)\n",
    "artist_pred_dict = get_prediction_for_artist(list(yval), yval_pred, artist_list)\n",
    "# evaluate the model for each artist with precision, recall and F1 score of the validation data\n",
    "evaluate_model(yval, yval_pred, 'MNB', artist_pred_dict, artist_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Save both models (pipelines) with pickle dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train models with full data and save it\n",
    "pipeline3.fit(df_train['lyrics_X'], df_train['artist_y'])\n",
    "pipeline4.fit(df_train['lyrics_X'], df_train['artist_y'])\n",
    "# saving RandomForestClassifier\n",
    "with open(\"model_RFC.pickle\",\"wb\") as file:\n",
    "    pickle.dump(pipeline3,file)\n",
    "# saving NaiveBayesClassifier\n",
    "with open(\"model_MNB.pickle\",\"wb\") as file:\n",
    "    pickle.dump(pipeline4,file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d01013faa6268d9b541af39e21e51ae91e81e71b63bd76f73433c553979f7595"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
